{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 8: How to find the best model parameters in Sci-kit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agenda\n",
    "\n",
    "-How can K-fold cross-validation be used to search for an optimal tuning parameter?\n",
    "\n",
    "-How can this process be made more efficient?\n",
    "\n",
    "-How do you search for multiple tuning parameters at once?\n",
    "\n",
    "-What do you do with those tuning parameters before making real predictions?\n",
    "\n",
    "-How can the computational expense of this process be reduced?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review of K-fold cross-validation\n",
    "\n",
    "**Steps for cross-validation:**\n",
    "\n",
    "1. Dataset is split into K \"folds\" of equal size\n",
    "\n",
    "2. Each fold acts as the testing set 1 time, and acts as the training set K-1 times\n",
    "\n",
    "3. Average testing performance is used as the estimate of out-of-sample performance\n",
    "\n",
    "**Benefits of cross-validation:**\n",
    "\n",
    "1. More reliable estimate of out-of-sample performance than train/test split\n",
    "\n",
    "2. Can be used for selecting tuning parameters, choosing between models, and selecting features\n",
    "   \n",
    "**Drawbacks of cross-validation:**\n",
    "\n",
    "1. Can be computationally expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review of Parameter tuning using cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "F:\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "scores = cross_val_score(knn, X, y, cv = 10, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.93333333, 1.        , 1.        , 0.86666667,\n",
       "       0.93333333, 0.93333333, 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666668"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for an optimal value of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1,31)\n",
    "k_score = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    scores = cross_val_score(knn, X, y, cv = 10, scoring = \"accuracy\")\n",
    "    k_score.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.96,\n",
       " 0.9533333333333334,\n",
       " 0.9666666666666666,\n",
       " 0.9666666666666666,\n",
       " 0.9666666666666668,\n",
       " 0.9666666666666668,\n",
       " 0.9666666666666668,\n",
       " 0.9666666666666668,\n",
       " 0.9733333333333334,\n",
       " 0.9666666666666668,\n",
       " 0.9666666666666668,\n",
       " 0.9733333333333334,\n",
       " 0.9800000000000001,\n",
       " 0.9733333333333334,\n",
       " 0.9733333333333334,\n",
       " 0.9733333333333334,\n",
       " 0.9733333333333334,\n",
       " 0.9800000000000001,\n",
       " 0.9733333333333334,\n",
       " 0.9800000000000001,\n",
       " 0.9666666666666666,\n",
       " 0.9666666666666666,\n",
       " 0.9733333333333334,\n",
       " 0.96,\n",
       " 0.9666666666666666,\n",
       " 0.96,\n",
       " 0.9666666666666666,\n",
       " 0.9533333333333334,\n",
       " 0.9533333333333334,\n",
       " 0.9533333333333334]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cross Validation score')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(k_range,k_score)\n",
    "plt.xlabel(\"Value of K\")\n",
    "plt.ylabel(\"Cross Validation score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Efficient parameter tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV allows you to define a set of parameters that we want to try with a given model and it will automatically run cross validation using each of those parameters keeping track of the resulting scores\n",
    "Essentially, it replaces the for loop in the above code as well as providing some additional functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV # GridsearcCV is the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(1, 31)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameter values that should be serached\n",
    "k_range = range(1,31)\n",
    "k_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': range(1, 31)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a parameter grid: It is a python dictionary in which the key is the parameter name \n",
    "# and the values are the list of values that need to be searched for that parameter.\n",
    "\n",
    "param_grid = dict(n_neighbors = k_range)\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid: It has the same parameters as the cross_val_score but it does not include X or y \n",
    "# But it does include param_grid\n",
    "# Please note that grid is an OBJECT\n",
    "\n",
    "grid = GridSearchCV(knn, param_grid, cv = 10, scoring =\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of grid as follows its an object ready to do 10 fold cross validation on a KNN model using classification accuracy as the evaluation metrics.\n",
    "Additionally, it has been given this param_grid parameter so that it knows it has to repeat the 10 fold cross val process 30 times and each time the n_neighbors parameter should be given a different value from the list\n",
    "\n",
    "That is why the parameter grid is a dict of key:value pairs. We cant just give GridSearchCV a list of numbers because it will not know what to do with those numbers. Instead, we have to specify which model parameter in this case n_neighbors should take the values 1 to 30. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=30, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_neighbors': range(1, 31)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='accuracy',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fit the grid with data\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Note**: If the computer supports parallel processing then we can set n_jobs = -1 to run parallel computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.052068</td>\n",
       "      <td>{'n_neighbors': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>{'n_neighbors': 14}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 16}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 17}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 18}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 19}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>{'n_neighbors': 21}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>{'n_neighbors': 22}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 23}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>{'n_neighbors': 24}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>{'n_neighbors': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>{'n_neighbors': 26}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 27}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.042687</td>\n",
       "      <td>{'n_neighbors': 28}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.042687</td>\n",
       "      <td>{'n_neighbors': 29}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.042687</td>\n",
       "      <td>{'n_neighbors': 30}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score               params\n",
       "0          0.960000        0.053333   {'n_neighbors': 1}\n",
       "1          0.953333        0.052068   {'n_neighbors': 2}\n",
       "2          0.966667        0.044721   {'n_neighbors': 3}\n",
       "3          0.966667        0.044721   {'n_neighbors': 4}\n",
       "4          0.966667        0.044721   {'n_neighbors': 5}\n",
       "5          0.966667        0.044721   {'n_neighbors': 6}\n",
       "6          0.966667        0.044721   {'n_neighbors': 7}\n",
       "7          0.966667        0.044721   {'n_neighbors': 8}\n",
       "8          0.973333        0.032660   {'n_neighbors': 9}\n",
       "9          0.966667        0.044721  {'n_neighbors': 10}\n",
       "10         0.966667        0.044721  {'n_neighbors': 11}\n",
       "11         0.973333        0.032660  {'n_neighbors': 12}\n",
       "12         0.980000        0.030551  {'n_neighbors': 13}\n",
       "13         0.973333        0.044222  {'n_neighbors': 14}\n",
       "14         0.973333        0.032660  {'n_neighbors': 15}\n",
       "15         0.973333        0.032660  {'n_neighbors': 16}\n",
       "16         0.973333        0.032660  {'n_neighbors': 17}\n",
       "17         0.980000        0.030551  {'n_neighbors': 18}\n",
       "18         0.973333        0.032660  {'n_neighbors': 19}\n",
       "19         0.980000        0.030551  {'n_neighbors': 20}\n",
       "20         0.966667        0.033333  {'n_neighbors': 21}\n",
       "21         0.966667        0.033333  {'n_neighbors': 22}\n",
       "22         0.973333        0.032660  {'n_neighbors': 23}\n",
       "23         0.960000        0.044222  {'n_neighbors': 24}\n",
       "24         0.966667        0.033333  {'n_neighbors': 25}\n",
       "25         0.960000        0.044222  {'n_neighbors': 26}\n",
       "26         0.966667        0.044721  {'n_neighbors': 27}\n",
       "27         0.953333        0.042687  {'n_neighbors': 28}\n",
       "28         0.953333        0.042687  {'n_neighbors': 29}\n",
       "29         0.953333        0.042687  {'n_neighbors': 30}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the complete result (list of named tuples)\n",
    "\n",
    "pd.DataFrame(grid.cv_results_)[[\"mean_test_score\", \"std_test_score\", \"params\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1}\n",
      "0.96\n",
      "0.053333333333333316\n"
     ]
    }
   ],
   "source": [
    "# examine the first result\n",
    "print(grid.cv_results_[\"params\"][0])\n",
    "print(grid.cv_results_[\"mean_test_score\"][0])\n",
    "print(grid.cv_results_[\"std_test_score\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of mean scores only\n",
    "\n",
    "grid_mean_score = grid.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96      , 0.95333333, 0.96666667, 0.96666667, 0.96666667,\n",
       "       0.96666667, 0.96666667, 0.96666667, 0.97333333, 0.96666667,\n",
       "       0.96666667, 0.97333333, 0.98      , 0.97333333, 0.97333333,\n",
       "       0.97333333, 0.97333333, 0.98      , 0.97333333, 0.98      ,\n",
       "       0.96666667, 0.96666667, 0.97333333, 0.96      , 0.96666667,\n",
       "       0.96      , 0.96666667, 0.95333333, 0.95333333, 0.95333333])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cross Validated accuracy')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(k_range, grid_mean_score)\n",
    "plt.xlabel(\"Value of K\")\n",
    "plt.ylabel(\"Cross Validated accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is identical to the plot that we created using a for loop.\n",
    "\n",
    "Writing a list comprehension and making a plot is not the most efficient way to view the results of a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "{'n_neighbors': 13}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=13, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# Once the grid is fit with data, it exposes 3 attributes that are very useful.\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_) # it is the actual model object fit with the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching multiple parameters simultaneously\n",
    "- Example: tuning max_depth and min_samples_leaf for a DecisionTreeClassifier\n",
    "- Could tune parameters independently: change max_depth while leaving min_samples_leaf at its default value, and vice versa\n",
    "- But, best performance might be achieved when neither parameter is at its default value. That means both parameters have some value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter values that need to be searched\n",
    "k_range = range(1,31)\n",
    "weight_options = [\"uniform\", \"distance\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights parameter controls how the K nearest neighbors are weighted while making a prediction. The default option is \"uniform\" which means all the neighbors will be weighted equally. \"distance\" option weighs the neighbors as per the distance. The closer neighbors are given more weightage than the far away neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(n_neighbors = k_range, weights = weight_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': range(1, 31), 'weights': ['uniform', 'distance']}\n"
     ]
    }
   ],
   "source": [
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=30, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_neighbors': range(1, 31), 'weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the grid and fit the grid\n",
    "grid = GridSearchCV(knn, param_grid, cv = 10, scoring = \"accuracy\")\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>{'n_neighbors': 1, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>{'n_neighbors': 1, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.052068</td>\n",
       "      <td>{'n_neighbors': 2, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>{'n_neighbors': 2, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 3, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 3, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 4, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 4, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 6, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 6, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 7, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 7, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 8, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 8, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 9, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 9, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 10, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 10, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 11, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 11, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 12, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>{'n_neighbors': 12, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 13, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 13, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>{'n_neighbors': 14, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 14, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 15, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 15, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 16, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 16, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 17, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 17, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 18, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 18, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 19, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 19, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 20, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 20, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>{'n_neighbors': 21, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 21, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>{'n_neighbors': 22, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 22, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 23, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 23, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>{'n_neighbors': 24, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 24, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>{'n_neighbors': 25, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 25, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>{'n_neighbors': 26, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 26, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'n_neighbors': 27, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'n_neighbors': 27, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.042687</td>\n",
       "      <td>{'n_neighbors': 28, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 28, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.042687</td>\n",
       "      <td>{'n_neighbors': 29, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'n_neighbors': 29, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.042687</td>\n",
       "      <td>{'n_neighbors': 30, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>{'n_neighbors': 30, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score  \\\n",
       "0          0.960000        0.053333   \n",
       "1          0.960000        0.053333   \n",
       "2          0.953333        0.052068   \n",
       "3          0.960000        0.053333   \n",
       "4          0.966667        0.044721   \n",
       "5          0.966667        0.044721   \n",
       "6          0.966667        0.044721   \n",
       "7          0.966667        0.044721   \n",
       "8          0.966667        0.044721   \n",
       "9          0.966667        0.044721   \n",
       "10         0.966667        0.044721   \n",
       "11         0.966667        0.044721   \n",
       "12         0.966667        0.044721   \n",
       "13         0.966667        0.044721   \n",
       "14         0.966667        0.044721   \n",
       "15         0.966667        0.044721   \n",
       "16         0.973333        0.032660   \n",
       "17         0.973333        0.032660   \n",
       "18         0.966667        0.044721   \n",
       "19         0.973333        0.032660   \n",
       "20         0.966667        0.044721   \n",
       "21         0.973333        0.032660   \n",
       "22         0.973333        0.032660   \n",
       "23         0.973333        0.044222   \n",
       "24         0.980000        0.030551   \n",
       "25         0.973333        0.032660   \n",
       "26         0.973333        0.044222   \n",
       "27         0.973333        0.032660   \n",
       "28         0.973333        0.032660   \n",
       "29         0.980000        0.030551   \n",
       "30         0.973333        0.032660   \n",
       "31         0.973333        0.032660   \n",
       "32         0.973333        0.032660   \n",
       "33         0.980000        0.030551   \n",
       "34         0.980000        0.030551   \n",
       "35         0.973333        0.032660   \n",
       "36         0.973333        0.032660   \n",
       "37         0.980000        0.030551   \n",
       "38         0.980000        0.030551   \n",
       "39         0.966667        0.044721   \n",
       "40         0.966667        0.033333   \n",
       "41         0.966667        0.044721   \n",
       "42         0.966667        0.033333   \n",
       "43         0.966667        0.044721   \n",
       "44         0.973333        0.032660   \n",
       "45         0.973333        0.032660   \n",
       "46         0.960000        0.044222   \n",
       "47         0.973333        0.032660   \n",
       "48         0.966667        0.033333   \n",
       "49         0.973333        0.032660   \n",
       "50         0.960000        0.044222   \n",
       "51         0.966667        0.044721   \n",
       "52         0.966667        0.044721   \n",
       "53         0.980000        0.030551   \n",
       "54         0.953333        0.042687   \n",
       "55         0.973333        0.032660   \n",
       "56         0.953333        0.042687   \n",
       "57         0.973333        0.032660   \n",
       "58         0.953333        0.042687   \n",
       "59         0.966667        0.033333   \n",
       "\n",
       "                                        params  \n",
       "0     {'n_neighbors': 1, 'weights': 'uniform'}  \n",
       "1    {'n_neighbors': 1, 'weights': 'distance'}  \n",
       "2     {'n_neighbors': 2, 'weights': 'uniform'}  \n",
       "3    {'n_neighbors': 2, 'weights': 'distance'}  \n",
       "4     {'n_neighbors': 3, 'weights': 'uniform'}  \n",
       "5    {'n_neighbors': 3, 'weights': 'distance'}  \n",
       "6     {'n_neighbors': 4, 'weights': 'uniform'}  \n",
       "7    {'n_neighbors': 4, 'weights': 'distance'}  \n",
       "8     {'n_neighbors': 5, 'weights': 'uniform'}  \n",
       "9    {'n_neighbors': 5, 'weights': 'distance'}  \n",
       "10    {'n_neighbors': 6, 'weights': 'uniform'}  \n",
       "11   {'n_neighbors': 6, 'weights': 'distance'}  \n",
       "12    {'n_neighbors': 7, 'weights': 'uniform'}  \n",
       "13   {'n_neighbors': 7, 'weights': 'distance'}  \n",
       "14    {'n_neighbors': 8, 'weights': 'uniform'}  \n",
       "15   {'n_neighbors': 8, 'weights': 'distance'}  \n",
       "16    {'n_neighbors': 9, 'weights': 'uniform'}  \n",
       "17   {'n_neighbors': 9, 'weights': 'distance'}  \n",
       "18   {'n_neighbors': 10, 'weights': 'uniform'}  \n",
       "19  {'n_neighbors': 10, 'weights': 'distance'}  \n",
       "20   {'n_neighbors': 11, 'weights': 'uniform'}  \n",
       "21  {'n_neighbors': 11, 'weights': 'distance'}  \n",
       "22   {'n_neighbors': 12, 'weights': 'uniform'}  \n",
       "23  {'n_neighbors': 12, 'weights': 'distance'}  \n",
       "24   {'n_neighbors': 13, 'weights': 'uniform'}  \n",
       "25  {'n_neighbors': 13, 'weights': 'distance'}  \n",
       "26   {'n_neighbors': 14, 'weights': 'uniform'}  \n",
       "27  {'n_neighbors': 14, 'weights': 'distance'}  \n",
       "28   {'n_neighbors': 15, 'weights': 'uniform'}  \n",
       "29  {'n_neighbors': 15, 'weights': 'distance'}  \n",
       "30   {'n_neighbors': 16, 'weights': 'uniform'}  \n",
       "31  {'n_neighbors': 16, 'weights': 'distance'}  \n",
       "32   {'n_neighbors': 17, 'weights': 'uniform'}  \n",
       "33  {'n_neighbors': 17, 'weights': 'distance'}  \n",
       "34   {'n_neighbors': 18, 'weights': 'uniform'}  \n",
       "35  {'n_neighbors': 18, 'weights': 'distance'}  \n",
       "36   {'n_neighbors': 19, 'weights': 'uniform'}  \n",
       "37  {'n_neighbors': 19, 'weights': 'distance'}  \n",
       "38   {'n_neighbors': 20, 'weights': 'uniform'}  \n",
       "39  {'n_neighbors': 20, 'weights': 'distance'}  \n",
       "40   {'n_neighbors': 21, 'weights': 'uniform'}  \n",
       "41  {'n_neighbors': 21, 'weights': 'distance'}  \n",
       "42   {'n_neighbors': 22, 'weights': 'uniform'}  \n",
       "43  {'n_neighbors': 22, 'weights': 'distance'}  \n",
       "44   {'n_neighbors': 23, 'weights': 'uniform'}  \n",
       "45  {'n_neighbors': 23, 'weights': 'distance'}  \n",
       "46   {'n_neighbors': 24, 'weights': 'uniform'}  \n",
       "47  {'n_neighbors': 24, 'weights': 'distance'}  \n",
       "48   {'n_neighbors': 25, 'weights': 'uniform'}  \n",
       "49  {'n_neighbors': 25, 'weights': 'distance'}  \n",
       "50   {'n_neighbors': 26, 'weights': 'uniform'}  \n",
       "51  {'n_neighbors': 26, 'weights': 'distance'}  \n",
       "52   {'n_neighbors': 27, 'weights': 'uniform'}  \n",
       "53  {'n_neighbors': 27, 'weights': 'distance'}  \n",
       "54   {'n_neighbors': 28, 'weights': 'uniform'}  \n",
       "55  {'n_neighbors': 28, 'weights': 'distance'}  \n",
       "56   {'n_neighbors': 29, 'weights': 'uniform'}  \n",
       "57  {'n_neighbors': 29, 'weights': 'distance'}  \n",
       "58   {'n_neighbors': 30, 'weights': 'uniform'}  \n",
       "59  {'n_neighbors': 30, 'weights': 'distance'}  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the results\n",
    "\n",
    "pd.DataFrame(grid.cv_results_)[[\"mean_test_score\", \"std_test_score\", \"params\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "{'n_neighbors': 13, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the best parameters to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=13, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train your model with all the data and the best known parameters. \n",
    "## All the data should be used so that you dont throw away the valuable data\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors= 13, weights = \"uniform\")\n",
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## making a prediction\n",
    "knn.predict([[3,5,4,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shortcut: GridSearchCV automatically refits the best model using all of the data\n",
    "grid.predict([[3,5,4,2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing computational expense using RandomizedSearchCV\n",
    "- Searching many different parameters at once may be computationally infeasible\n",
    "  For eg: search 10 parameter values for each of 4 parameters will require 10,000 trials of Cross_val which will lead to 1,00,000 model fits and 1,00,000 sets of predictions if 10 fold cv is used.\n",
    "- RandomizedSearchCV searches a subset of the parameters, and you control the computational \"budget\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For RandomizedSearchCV we specify \"parameter dictribution\" rather than \"parameter grid\"\n",
    "# For discrete parameters, param_dist is same as param_grid\n",
    "\n",
    "param_dist = dict(n_neighbors = k_range, weights = weight_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Specify a continuous distribution (rather than a list of values) for any continuous parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## n_iter controls the number of serches\n",
    "\n",
    "grid = RandomizedSearchCV(knn, param_dist, n_iter=10, cv = 10, scoring = \"accuracy\", random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise-deprecating',\n",
       "          estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=13, p=2,\n",
       "           weights='uniform'),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=None,\n",
       "          param_distributions={'n_neighbors': range(1, 31), 'weights': ['uniform', 'distance']},\n",
       "          pre_dispatch='2*n_jobs', random_state=5, refit=True,\n",
       "          return_train_score='warn', scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 16}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 22}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 18}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 27}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.042687</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 29}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 22}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 14}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 15}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  std_test_score                                      params\n",
       "0         0.973333        0.032660  {'weights': 'distance', 'n_neighbors': 16}\n",
       "1         0.966667        0.033333   {'weights': 'uniform', 'n_neighbors': 22}\n",
       "2         0.980000        0.030551   {'weights': 'uniform', 'n_neighbors': 18}\n",
       "3         0.966667        0.044721   {'weights': 'uniform', 'n_neighbors': 27}\n",
       "4         0.953333        0.042687   {'weights': 'uniform', 'n_neighbors': 29}\n",
       "5         0.973333        0.032660  {'weights': 'distance', 'n_neighbors': 10}\n",
       "6         0.966667        0.044721  {'weights': 'distance', 'n_neighbors': 22}\n",
       "7         0.973333        0.044222   {'weights': 'uniform', 'n_neighbors': 14}\n",
       "8         0.973333        0.044222  {'weights': 'distance', 'n_neighbors': 12}\n",
       "9         0.973333        0.032660   {'weights': 'uniform', 'n_neighbors': 15}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)[[\"mean_test_score\", \"std_test_score\", \"params\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': 'uniform', 'n_neighbors': 18}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Classification models: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Agenda\n",
    "- What is the purpose of model evaluation, and what are some common evaluation procedures?\n",
    "- What is the usage of classification accuracy, and what are its limitations?\n",
    "- How does a confusion matrix describe the performance of a classifier?\n",
    "- What metrics can be computed from a confusion matrix?\n",
    "- How can you adjust classifier performance by changing the classification threshold?\n",
    "- What is the purpose of an ROC curve?\n",
    "- How does Area Under the Curve (AUC) differ from classification accuracy?\n",
    "\n",
    "### Review of model evaluation\n",
    "- Need a way to choose between models: different model types, tuning parameters, and features\n",
    "- Use a model evaluation procedure to estimate how well a model will generalize to out-of-sample data\n",
    "- Requires a model evaluation metric to quantify the model performance\n",
    "\n",
    "### Model evaluation procedures\n",
    "**Training and testing on the same data**\n",
    "- Rewards overly complex models that \"overfit\" the training data and won't necessarily generalize\n",
    "\n",
    "**Train/test split**\n",
    "- Split the dataset into two pieces, so that the model can be trained and tested on different data\n",
    "- Better estimate of out-of-sample performance, but still a \"high variance\" estimate\n",
    "- Useful due to its speed, simplicity, and flexibility\n",
    "\n",
    "**K-fold cross-validation**\n",
    "- Systematically create \"K\" train/test splits and average the results together\n",
    "- Even better estimate of out-of-sample performance\n",
    "- Runs \"K\" times slower than train/test split\n",
    "\n",
    "**Model evaluation metrics**\n",
    "- Regression problems: Mean Absolute Error, Mean Squared Error, Root Mean Squared Error\n",
    "- Classification problems: Classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are many other evaluation metrics for classification and those metrics are the focus of todays video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "pima = pd.read_csv(\"C:/Users/Ashish/Desktop/Python Tutorials/CSV files/diabetes.csv\", header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pregnant glucose  bp skin insulin   bmi pedigree age label\n",
       "1        6     148  72   35       0  33.6    0.627  50     1\n",
       "2        1      85  66   29       0  26.6    0.351  31     0\n",
       "3        8     183  64    0       0  23.3    0.672  32     1\n",
       "4        1      89  66   23      94  28.1    0.167  21     0\n",
       "5        0     137  40   35     168  43.1    2.288  33     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.drop(index = 0, axis = 0, inplace = True)\n",
    "pima.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. Can we predict the diabetes status of a patient given their health measurements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"pregnant\", \"insulin\", \"bmi\", \"age\"]\n",
    "X = pima[feature_cols]\n",
    "y = pima.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6927083333333334"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null accuracy: accuracy that could be achieved by always predicting the most frequent class\n",
    "    \n",
    "whenever we use classification accuracy as our evaluation metric, its necessary to compare it with null accuracy which is the accuracy that could be achieved by always predicting the most frequent class of the testing set\n",
    "\n",
    "Lets calculate the null accuracy for this dataset to see why this is a useful comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the ditribution of the testing set (by using pandas series)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null Accuracy answers the question:\n",
    "if my model was to predict the most predominant class 100% of the time (0 in this case), then how often would it be correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.2135473964062504e+188"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the percentage of ones\n",
    "y_test.mean() # The answer should be (62/192) = 0.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.2135473964062504e+188"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the percentage of zeros\n",
    "1 - y_test.mean() # The answer should be (1 - 0.32) = 0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.2135473964062504e+188"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy (for binary classification problems coded as 0/1)\n",
    "max(y_test.mean(), 1 - y_test.mean()) # The answer should be 0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.677083\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy (for multi-class classification problems 3 or more classes)\n",
    "y_test.value_counts().head(1) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 68% > 32%, we can say that 68% is the null accuracy for this problem\n",
    "\n",
    "In other words, a dumb model which always predicts that the patient does not have diabetes will be right 68% of the time. When we compare the null accuracy of 68% to model accuracy of 69%, our model is no longer a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True : ['1' '0' '0' '1' '0' '0' '1' '1' '0' '0' '1' '1' '0' '0' '0' '0' '1' '0'\n",
      " '0' '0' '1' '1' '0' '0' '0']\n",
      "Pred : ['0' '0' '0' '0' '0' '0' '0' '1' '0' '1' '0' '1' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0']\n"
     ]
    }
   ],
   "source": [
    "# Weakness of Classification accuracy\n",
    "# print the first 25 true and predicted responses\n",
    "print(\"True :\", y_test.values[0:25])\n",
    "print(\"Pred :\", y_pred[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above code we can observe a pattern that when a true response value is 0 the model almost always predicts a 0. But when true response value is 1, the model rarely predicts a 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is making certin type of errors but not others. But we will never come to know that simply by measuring the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "- Classification accuracy is the easiest classification metric to understand\n",
    "- But, it does not tell you the underlying distribution of response values\n",
    "- And, it does not tell you what \"types\" of errors your classifier is making which is often important to know in real world situations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###                         Confusion matrix\n",
    "  **Table that describes the performance of a classification model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[118,  12],\n",
       "       [ 47,  15]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT: first argument for confusion matrix is true values(y_test), second argument is predicted values(y_pred) ALWAYS. If we pass predicted values first, then it would flip the table completely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix is a tally of two types of correct predictions that the classifier can make as well as the tally of two types of incorrect predictions that a classifier can make \n",
    "\n",
    "- Every observation in the testing set is represented in exactly one box\n",
    "- It's a 2x2 matrix because there are 2 response classes. If there were 5 response classes then the matrix would be 5x5 matrix\n",
    "- The format shown here is not universal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a BINARY problem only, each of these boxes has a specific name, which is useful to memorise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic terminology**\n",
    "\n",
    "- True Positives (TP): we correctly predicted that they do have diabetes[**Bottom Right**] indicates that in 15 cases the model correctly predicted that the patient has diabetes\n",
    "- True Negatives (TN): we correctly predicted that they don't have diabetes[**Upper left**] indicates that in 118 cases, the model correctly predicted that the patient does not have diabetes\n",
    "- False Positives (FP): we incorrectly predicted that they do have diabetes (a \"Type I error\") [**Upper right**] indicates that in 12 cases, the model incorrectly predicted that the patient has diabetes\n",
    "- False Negatives (FN): we incorrectly predicted that they don't have diabetes (a \"Type II error\") [**Bottom left**] in 47 cases, the model incorrectly predicted that the patient does not have diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: The class encoded as 1 should be taken as positive class and class encoded as 0 should be taken as negative class\n",
    "    \n",
    "Thats why correctly predicting 1 is called True positive and correctly predicting 0 is called True negative    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the confusion matrix and slice it into 4 pieces\n",
    "confusion = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1]\n",
    "TN = confusion[0,0]\n",
    "FP = confusion[0,1]\n",
    "FN = confusion[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix is useful in helping you to understand the performance of your classifier. But how can it help you to choose between models? Its not a model evaluation metric. So you cant simply tell scikit learn to choose the model with the best confusion matrix. However, there are many matrix that can be calculated from a confusion matrix, and those can be directly used to choose between models. Lets go through a few of the popular matrix and then at the end talk about how to choose which matrix to optimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Computed from Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Classification accuracy:** How often the classifier is correct??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6927083333333334"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification accuracy\n",
    "(TP+TN)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6927083333333334"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The accuracy score function in metrics module, does the same thing\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Classification Error:** How often is the classifier incorrect?? \n",
    "\n",
    "Also known as \"Misclassification Rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3072916666666667"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification Error\n",
    "(FP+FN)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30729166666666663"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is same as 1-classification accuracy\n",
    "1 - accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Sensitivity:** When the actual value is positive, how often is the prediction correct??\n",
    "    \n",
    "\n",
    "  - How sensitive is the classifier in detecting the positive instances?\n",
    "  - Also known as \"True Positive Rate\" or \"Recall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24193548387096775"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP/(FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24193548387096775"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred, pos_label = '1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Specificity:** When the actual value is negative, how often is the prediction correct?\n",
    "\n",
    "How \"specific\" (or \"selective\") is the classifier in predicting positive instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9076923076923077"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Spec = TN/(TN + FP)\n",
    "Spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We would want to maximize the value of Sesitivity and Specificity.\n",
    "- The max value of sensitivity and specificity is 1\n",
    "- Hence the above classifier can be described as highly specific but not highly sensitive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **False Positive Rate:** When the actual value is negative, how often is the prediction **incorrect**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09230769230769231"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP/(TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09230769230769231"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False positive rate = 1 - Specificity\n",
    "1 - Spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Precision:** When a positive value is predicted, how often is the prediction correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5555555555555556"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5555555555555556"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred, pos_label = '1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precesion = True Positive / Actual Results\n",
    "\n",
    "Recall = True Positive / Predicted value\n",
    "\n",
    "Recall: How many times the classifier predicted the **correct positive** value.\n",
    "Precision: Out of the total number of times classifier predicted the correct positive value, how many times was he correct?\n",
    "\n",
    "Example of Precision and Recall:\n",
    "What are the chances that Jack will be able to recall all such instances where he shared his bank details precisely? If you understood what I asked in the previous sentence with a cent per cent confidence, you have probably understood what recall and precision actually means. But, just to double check, here is my analysis. if Jack had lets say ten such instances in reality, and he narrated twenty instances to finally spell out the ten correct instances, then his recall will be a 100%, but his precision will only be 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Always use a confusion matrix for your classifier\n",
    "- Confusion matrix gives you a more complete picture of how your classifier is performing\n",
    "- Also allows you to compute various classification metrics, and these metrics can guide your model selection\n",
    "\n",
    "**Which metrics should you focus on?**\n",
    "\n",
    "We can optimize for any of the given metric\n",
    "\n",
    "Choice of metric depends on your business objective\n",
    "- Spam filter (positive class is \"spam\"): Optimize for precision or specificity because false negatives (spam goes to the inbox) are more acceptable than false positives (non-spam is caught by the spam filter)\n",
    "\n",
    "- Fraudulent transaction detector (positive class is \"fraud\"): Optimize for sensitivity because false positives (normal transactions that are flagged as possible fraud) are more acceptable than false negatives (fraudulent transactions that are not detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting the Classification Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '0', '0', '0', '0', '0', '0', '1', '0', '1'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict(X_test)[0:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict_proba outputs predicted probabilities of class membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63247571, 0.36752429],\n",
       "       [0.71643656, 0.28356344],\n",
       "       [0.71104114, 0.28895886],\n",
       "       [0.5858938 , 0.4141062 ],\n",
       "       [0.84103973, 0.15896027],\n",
       "       [0.82934844, 0.17065156],\n",
       "       [0.50110974, 0.49889026],\n",
       "       [0.48658459, 0.51341541],\n",
       "       [0.72321388, 0.27678612],\n",
       "       [0.32810562, 0.67189438]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(X_test)[0:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each row represents one observation and each column represents a particular class. \n",
    "- There are 2 columns as there are 2 possible response classes 0 and 1 \n",
    "- The first col represents the probility that the observation belongs to class 0\n",
    "- The second col represents the probility that the observation belongs to class 1\n",
    "\n",
    "\n",
    "- **Why might we care about the predicted probabilities?**\n",
    "- Since this model predicts the likelihood of diabetes, we might rank the observations based on predicted probabilty of daabetes and prioritize our patient preventive outreach accordingly. Since it makes more sense to contact someone with 95% chance of diabetes than a 55% chance\n",
    "\n",
    "\n",
    "- It seems that when we run the predict method for logistic regression, it first finds out the prob of each class and then chooses the class with highest probabilty as the predicted response. \n",
    "\n",
    "\n",
    "- Another way to look at it is, when there is a binary problem like this one, there is a threshold value set at 50%. If the prob exceeds 50% then it is predicted as 1 or else it is predicted as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36752429, 0.28356344, 0.28895886, 0.4141062 , 0.15896027,\n",
       "       0.17065156, 0.49889026, 0.51341541, 0.27678612, 0.67189438])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted prob of class 1\n",
    "logreg.predict_proba(X_test)[0:10, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the predicted probabilities for class 1\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are now going to plot the histogram of these probabilities to help demonstrate, how adjusting the classification threshold can impact the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of predicted probabilities\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(y_pred_prob , bins = 8)\n",
    "plt.xlim(0,1)\n",
    "plt.title(\"Histogram of predicted probabilities\")\n",
    "plt.xlabel(\"Predicted prob of diabetes\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.rcParams[\"font.size\"] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the histogram it is clear that, very few observations have prob of more than 0.50\n",
    "- Maximum observations (around 45) have a prob of 0.3\n",
    "- If we change the value of threshold, we can change the value of **Sensitivity** and **Specificity** as per our requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decrease the THRESHOLD to increase the SENSITIVITY of the classifier\n",
    "\n",
    "- Threshold has been set to 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict diabetes if the predicted prob is greater than 0.3\n",
    "from sklearn.preprocessing import binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = binarize([y_pred_prob], 0.3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36752429, 0.28356344, 0.28895886, 0.4141062 , 0.15896027,\n",
       "       0.17065156, 0.49889026, 0.51341541, 0.27678612, 0.67189438])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.0', '0.0', '0.0', '1.0', '0.0', '0.0', '1.0', '1.0', '0.0',\n",
       "       '1.0', '1.0', '1.0', '1.0', '0.0', '1.0', '0.0', '1.0', '0.0',\n",
       "       '1.0', '1.0', '1.0', '1.0', '0.0', '1.0', '0.0', '0.0', '0.0',\n",
       "       '1.0', '0.0', '0.0', '1.0', '1.0', '0.0', '1.0', '0.0', '1.0',\n",
       "       '1.0', '0.0', '0.0', '1.0', '0.0', '1.0', '0.0', '0.0', '1.0',\n",
       "       '0.0', '0.0', '0.0', '1.0', '0.0', '1.0', '0.0', '1.0', '1.0',\n",
       "       '1.0', '0.0', '0.0', '1.0', '0.0', '0.0', '1.0', '1.0', '0.0',\n",
       "       '0.0', '0.0', '1.0', '1.0', '0.0', '1.0', '1.0', '0.0', '0.0',\n",
       "       '0.0', '1.0', '1.0', '0.0', '1.0', '1.0', '0.0', '1.0', '1.0',\n",
       "       '1.0', '0.0', '0.0', '1.0', '1.0', '0.0', '1.0', '1.0', '1.0',\n",
       "       '0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '1.0', '1.0', '1.0',\n",
       "       '1.0', '1.0', '0.0', '1.0', '0.0', '1.0', '1.0', '0.0', '0.0',\n",
       "       '0.0', '0.0', '0.0', '1.0', '1.0', '0.0', '1.0', '1.0', '0.0',\n",
       "       '0.0', '0.0', '1.0', '1.0', '1.0', '1.0', '1.0', '0.0', '0.0',\n",
       "       '1.0', '1.0', '1.0', '0.0', '0.0', '0.0', '0.0', '1.0', '1.0',\n",
       "       '1.0', '0.0', '1.0', '0.0', '0.0', '0.0', '1.0', '0.0', '1.0',\n",
       "       '1.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '1.0', '0.0',\n",
       "       '0.0', '1.0', '0.0', '1.0', '0.0', '1.0', '1.0', '1.0', '1.0',\n",
       "       '0.0', '0.0', '1.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0',\n",
       "       '1.0', '0.0', '1.0', '1.0', '0.0', '1.0', '1.0', '0.0', '0.0',\n",
       "       '1.0', '1.0', '1.0', '1.0', '0.0', '0.0', '1.0', '0.0', '0.0',\n",
       "       '0.0', '0.0', '0.0'], dtype='<U32')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_pred).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '0', '0', '1', '0', '0', '1', '1', '0', '0', '1', '1', '0',\n",
       "       '0', '0', '0', '1', '0', '0', '0', '1', '1', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0',\n",
       "       '0', '0', '0', '0', '1', '1', '0', '0', '1', '1', '1', '0', '0',\n",
       "       '1', '0', '0', '0', '0', '1', '1', '1', '1', '0', '0', '1', '1',\n",
       "       '1', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '1', '0', '1', '1', '0', '0', '0', '0',\n",
       "       '0', '1', '0', '0', '0', '1', '0', '1', '1', '1', '1', '1', '0',\n",
       "       '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0',\n",
       "       '0', '0', '0', '1', '0', '1', '0', '1', '1', '0', '0', '0', '0',\n",
       "       '0', '1', '0', '0', '0', '0', '1', '0', '1', '0', '0', '1', '0',\n",
       "       '0', '0', '1', '1', '1', '1', '0', '0', '0', '1', '0', '0', '0',\n",
       "       '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '1', '1',\n",
       "       '0', '1', '1', '0', '1', '1', '1', '0', '0', '0'], dtype='<U1')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(y_test).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  12]\n",
      " [ 47  15]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    96\n",
       "1.0    96\n",
       "dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_pred).value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662    1\n",
       "123    0\n",
       "114    0\n",
       "15     1\n",
       "530    0\n",
       "104    0\n",
       "339    1\n",
       "589    1\n",
       "396    0\n",
       "205    0\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 0., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-204-430e012b2078>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0munique_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munion1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_values\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m                 \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munion1d\u001b[1;34m(ar1, ar2)\u001b[0m\n\u001b[0;32m    736\u001b[0m     \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m     \"\"\"\n\u001b[1;32m--> 738\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mar2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Could not find the answer for this error\n",
    "\n",
    "- The result should:\n",
    "   \n",
    "   [[80,50]\n",
    "    \n",
    "    [16,46]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Sensitivity and Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7419354838709677"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sensitivity\n",
    "\n",
    "46/(46+16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6153846153846154"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specificity\n",
    "\n",
    "80/(80+50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Threshold of 0.5 is used by default (for binary problems) to convert predicted probabilities into class predictions\n",
    "- Threshold can be adjusted to increase sensitivity or specificity\n",
    "- Sensitivity and specificity have an inverse relationship. Inceasing one, will always decrease the other\n",
    "\n",
    "Adjusting the threshold is one of the last steps we should take in the model building process. majority of the time should be given to building better models and selecting the best possible model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curves and Area Under the Curve (AUC)\n",
    "\n",
    "**Question:** Wouldn't it be nice if we could see how sensitivity and specificity are affected by various thresholds, without actually changing the threshold?\n",
    "\n",
    "**Answer:** Plot the ROC curve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label = \"1\")\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.title(\"ROC curve for diabetes classifier\")\n",
    "plt.xlabel(\"False Positive Rate (1-specificity)\")\n",
    "plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is a plot of Sensitivity on y-axis and 1-specificity on x-axis for all possible values of thresholds between 0 to 1\n",
    "- For eg: the plot tells us that if we want to achieve a sensitivity of 0.9, we have to be willing to accept the specificty of (1-0.8) = 0.2\n",
    "- The optimal ROC curve hugs the upper left corner of the plot since that would represent a classifier with high sensitivity and high specificity    \n",
    "- ROC curve can help you to choose a threshold that balances sensitivity and specificity in a way that makes sense for your particular context\n",
    "- You can't actually see the thresholds used to generate the curve on the ROC curve itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts a threshold and prints sensitivity and specificity\n",
    "def evaluate_threshold(threshold):\n",
    "    print('Sensitivity:', tpr[thresholds > threshold][-1])\n",
    "    print('Specificity:', 1 - fpr[thresholds > threshold][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.7419354838709677\n",
      "Specificity: 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "evaluate_threshold(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.7419354838709677\n",
      "Specificity: 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "evaluate_threshold(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC: Area under the Curve\n",
    "\n",
    "AUC literally means area under the ROC curve meaning the percentage of graph which is under ROC curve. As the ideal classifier would hug the upper left corner of the graph, a higher AUC value is indicative of a better overall classifier. AUC is often used as a single number summary of the performance of a classifier. AUC can be used as an alternative to classification accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6786600496277917\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The best possible value for AUC is 1. if the AUC value is closer to 1, it means that we have a good classifer overall.\n",
    "- If you randomly chose one positive and one negative observation, AUC represents the likelihood that your classifier will assign a higher predicted probability to the positive observation.\n",
    "- AUC is useful even when there is high class imbalance (unlike classification accuracy). High class imbalance means one of the class is very large as compared to other. \n",
    "- For eg: If we are predicting fradulant transactions, that time, in most of the data, the transaction will not be fraudulant. Hence null accuracy will be 99% and hence classification accuracy wont be a useful measurement. AUC will be used that time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC can be used as a scoring function for cross-val score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7378233618233618"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logreg, X, y, cv=10, scoring = \"roc_auc\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix advantages:**\n",
    "\n",
    "- Allows you to calculate a variety of metrics\n",
    "- Useful for multi-class problems (more than two response classes)\n",
    "\n",
    "**ROC/AUC advantages:**\n",
    "\n",
    "- Does not require you to set a classification threshold\n",
    "- Still useful when there is high class imbalance\n",
    "- Less interpretable during multi-class problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video 10: How do I encode categorical features using Scikit-learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline: The point of pipeline is to chain the steps together sequentially. Normally, we put preprocessing steps and model building steps in pipeline\n",
    "    \n",
    "- **Why should we build a pipeline?** \n",
    "- 2 reasons:\n",
    "    1. It allows us to properly cross-validate a **process** rather than just the model. A process includes both pre-processing        and model building.\n",
    "    2. We can do a grid search or a randomized search of a pipeline which allows us to do a grid or randomized search for both        tuning parameters of a model and preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"http://bit.ly/kaggletrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex Embarked\n",
       "0         0       3    male        S\n",
       "1         1       1  female        C\n",
       "2         1       3  female        S\n",
       "3         1       1  female        S\n",
       "4         0       3    male        S"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting features\n",
    "df.loc[:, [\"Survived\", \"Pclass\", \"Sex\", \"Embarked\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 2 rows where embarked = 0. Hence we will remove those rows\n",
    "\n",
    "df = df.loc[df.Embarked.notna(), [\"Survived\", \"Pclass\", \"Sex\", \"Embarked\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 4)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Pclass      0\n",
       "Sex         0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex Embarked\n",
       "0         0       3    male        S\n",
       "1         1       1  female        C\n",
       "2         1       3  female        S\n",
       "3         1       1  female        S\n",
       "4         0       3    male        S"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will first start by cross-validating a model to predict survive using only the \"Pclass\"\n",
    "# After that, we will use pipeline, one hot encoder and column transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, [\"Pclass\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 1)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # Even if we have only one feature in X, it has to be 2 dimensional. Hence shape is 889,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889,)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver = \"lbfgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6783580183861082"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logreg, X, y, cv = 10, scoring = \"accuracy\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.617548\n",
       "1    0.382452\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing cross val accuracy with null accuracy\n",
    "y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is the basic cross val model \n",
    "\n",
    "**Q. Now, I want to add more features to my model and cross validate it.**\n",
    "\n",
    "Ans. We have to use pipeline\n",
    "\n",
    "- But before that, we have to first talk about encoding the sex column and Embarked column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For encoding categorical features if they are unordered, usually the best approach is **\"Dummy encoding\"** in python which is also known as **\"One Hot Encoding\"** in scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneHotEncoder like any Scikit Learn transformer has a fit and a transform method. And a Fit-transform that allows you to do both at the same time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.fit_transform(df[[\"Sex\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['female', 'male'], dtype=object)]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.fit_transform(df[[\"Embarked\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['C', 'Q', 'S'], dtype=object)]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we would use pipline to do **\"One Hot Encoding\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Survived\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex Embarked\n",
       "0       3    male        S\n",
       "1       1  female        C\n",
       "2       3  female        S\n",
       "3       1  female        S\n",
       "4       3    male        S"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import column transformer\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We use column transformer anytime we have features in the dataframe that require different pre-processing. This means \"OneHot Encoding\" is a pre-processing step. We want to apply it to \"Embarked\" and \"Sex\" columns and not on \"Pclass\" column as Pclass column is a numeric variable and not a categorical variable.\n",
    "- Hence we will be creating a column transformer that accomplishes that objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans = make_column_transformer((OneHotEncoder(), [\"Sex\", \"Embarked\"]), remainder = \"passthrough\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above code means as follows:\n",
    "- I make a column transformer which says I want to apply a OneHotEncoder on \"Sex\" and \"Embarked\" columns of the dataframe, and the remainder of the columns I want to pass through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1., 3.],\n",
       "       [1., 0., 1., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 1., 3.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 1., 3.],\n",
       "       [0., 1., 1., 0., 0., 1.],\n",
       "       [0., 1., 0., 1., 0., 3.]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_trans.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output:\n",
    "    1. The first two columns are OneHotEncoded columns for Sex\n",
    "    2. The next 3 columns are onehotencoded columns for embarked\n",
    "    3. The final column is the pass-through of Pclass column because we didnt want to encode it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(column_trans, logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important:\n",
    "    1. Pipeline is for chaining steps together. So we have created a pipeline that does the following things:\n",
    "    2. It takes my data that I pass it, transforms the columns which is my preprocessing step and then it builds my logreg            model.\n",
    "    3. Now we will pass the entire pipeline to the cross-val score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7705183861082737"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, X,y,cv=10, scoring = \"accuracy\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy increased from 67% to 77% meaning, the accuracy imporved by adding \"Sex\" and \"Embarked\" columns in the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What happens when we run the above line of code? \n",
    "- This means I am cross-validating my entire pipeline. In other words, I am not cross-validating a model, I am cross-validating a pipeline of steps that includes pre-processing of data and model building. In other words, cross val score is going to do my 10 fold split of data and then after it splits the data it will then run the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions on **\"New** Data\" whether they surivived or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X.sample(5, random_state = 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex Embarked\n",
       "599       1    male        C\n",
       "512       1    male        S\n",
       "273       1    male        C\n",
       "215       1  female        C\n",
       "790       3    male        Q"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normally if we have built our model and evaluated it using test dataset and then we want to make predictions then what do we do? We do model.fit()\n",
    "- But now we do not have a model. We have a pipeline that includes a model. So we do pipe.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('columntransformer', ColumnTransformer(n_jobs=None, remainder='passthrough', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('onehotencoder', OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error...enalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pipe.fit is same as model.fit except it runs the pre-processing as well as the model fitting\n",
    "- pipe.predict is just as model.predict except it runs pre-processing on X_new\n",
    "- X_new has string series present. It converts the strings to numbers with OneHotEncoding and then does the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. Why using OneHotEncoder, column transformer and pipeline better than using \"get-dummies\" in python ??\n",
    "\n",
    "Ans. There are 4 reasons:\n",
    "    1. We dont have to create a giagantic dataframe. OneHotEncoder does not effect our dataframe. Our dataframe remains the same and hence it is easier to manage.\n",
    "    2. When new data comes in, we dont have to use \"get-dummies\" on it. Because in get-dummies, whenever an out-of-sample data comes in, we have to use get-dummies on it. Also, if the in-sample series contains 3 classes say (C,Q,S) and out-of-sample data contains 2 classes (Q and S) then it will cause problems\n",
    "    3. We can do gridsearch on both model parameter and pre-processing parameters\n",
    "    4. In some cases, doing cross-validation outside scikit learn can make the cross-val scores less reliable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap of OneHotEncoder, Pipeline and Column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"http://bit.ly/kaggletrain\")\n",
    "df = df.loc[df.Embarked.notna(), [\"Survived\", \"Pclass\", \"Sex\", \"Embarked\"]]\n",
    "X = df.drop(\"Survived\", axis = 1)\n",
    "y = df.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "column_trans = make_column_transformer((OneHotEncoder(), [\"Sex\", \"Embarked\"]), remainder = \"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model creation\n",
    "logreg = LogisticRegression(solver = \"lbfgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting pre-processing and model inside a pipeline\n",
    "pipe = make_pipeline(column_trans, logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7705183861082737"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validate the entire pipeline\n",
    "cross_val_score(pipe, X,y,cv=10, scoring =\"accuracy\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X.sample(5 , random_state = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex Embarked\n",
       "815       1    male        S\n",
       "861       2    male        S\n",
       "539       1  female        C\n",
       "236       2    male        S\n",
       "876       3    male        S"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
